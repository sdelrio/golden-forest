"use strict";(self.webpackChunkgolden_forest_website=self.webpackChunkgolden_forest_website||[]).push([["729"],{35630:function(e,r,n){n.r(r),n.d(r,{frontMatter:()=>o,toc:()=>c,default:()=>d,metadata:()=>s,assets:()=>l,contentTitle:()=>a});var s=JSON.parse('{"id":"Develop-Code/AI-Workflows/Prompt-Library/System-Prompts-and-Personas","title":"Prompts & Persona","description":"Prompt Library & Persona Frameworks","source":"@site/docs/Develop-Code/AI-Workflows/Prompt-Library/System-Prompts-and-Personas.mdx","sourceDirName":"Develop-Code/AI-Workflows/Prompt-Library","slug":"/Develop-Code/AI-Workflows/Prompt-Library/System-Prompts-and-Personas","permalink":"/pr-preview/pr-71/docs/Develop-Code/AI-Workflows/Prompt-Library/System-Prompts-and-Personas","draft":false,"unlisted":false,"editUrl":"https://github.com/sdelrio/golden-forest/edit/master/docs/Develop-Code/AI-Workflows/Prompt-Library/System-Prompts-and-Personas.mdx","tags":[{"inline":true,"label":"LLM","permalink":"/pr-preview/pr-71/docs/tags/llm"},{"inline":true,"label":"Prompt-Engineering","permalink":"/pr-preview/pr-71/docs/tags/prompt-engineering"},{"inline":true,"label":"Reverse-Engineering","permalink":"/pr-preview/pr-71/docs/tags/reverse-engineering"},{"inline":true,"label":"AI-Ops","permalink":"/pr-preview/pr-71/docs/tags/ai-ops"}],"version":"current","frontMatter":{"title":"Prompts & Persona","category":"Develop-Code","sub-category":"AI-Workflows/Prompt-Library","tags":["LLM","Prompt-Engineering","Reverse-Engineering","AI-Ops"]},"sidebar":"tutorialSidebar","previous":{"title":"Prompt Library","permalink":"/pr-preview/pr-71/docs/category/prompt-library"},"next":{"title":"45 Prompts for Gemini 3","permalink":"/pr-preview/pr-71/docs/Develop-Code/AI-Workflows/Prompt-Library/gemini-prompts"}}'),i=n(74848),t=n(84429);let o={title:"Prompts & Persona",category:"Develop-Code","sub-category":"AI-Workflows/Prompt-Library",tags:["LLM","Prompt-Engineering","Reverse-Engineering","AI-Ops"]},a,l={},c=[{value:"Prompt Library &amp; Persona Frameworks",id:"prompt-library--persona-frameworks",level:2},{value:"1. System Prompt Analysis",id:"1-system-prompt-analysis",level:3},{value:"2. Persona Construction Strategy",id:"2-persona-construction-strategy",level:3},{value:"Technical Critique: Implementation Realities",id:"technical-critique-implementation-realities",level:2},{value:"1. Learning Curves",id:"1-learning-curves",level:3},{value:"2. Hardware and Performance Dependencies",id:"2-hardware-and-performance-dependencies",level:3},{value:"3. Operational Risks",id:"3-operational-risks",level:3}];function p(e){let r={a:"a",em:"em",h2:"h2",h3:"h3",hr:"hr",li:"li",p:"p",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(r.h2,{id:"prompt-library--persona-frameworks",children:"Prompt Library & Persona Frameworks"}),"\n",(0,i.jsx)(r.h3,{id:"1-system-prompt-analysis",children:"1. System Prompt Analysis"}),"\n",(0,i.jsx)(r.p,{children:(0,i.jsxs)(r.em,{children:["Source: ",(0,i.jsx)(r.a,{href:"https://github.com/asgeirtj/system_prompts_leaks",children:"System Prompts Leaks (GitHub)"})]})}),"\n",(0,i.jsx)(r.p,{children:"Analysis of Tier-1 AI system prompts (OpenAI, Anthropic, Google) reveals a standardized structural approach:"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Constraint Layers:"}),' Explicit "Do Not" lists that prevent the model from assuming unauthorized authority or violating safety protocols.']}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Tool Orchestration:"})," Detailed instructions on how to interact with sandboxed environments (Python, Web Search, Image Generation)."]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Reasoning Buffers:"}),' Encouraging the model to "think" or "plan" before providing a final response to improve logical consistency.']}),"\n"]}),"\n",(0,i.jsx)(r.h3,{id:"2-persona-construction-strategy",children:"2. Persona Construction Strategy"}),"\n",(0,i.jsx)(r.p,{children:(0,i.jsxs)(r.em,{children:["Source: ",(0,i.jsx)(r.a,{href:"https://www.proxet.com/blog/using-llms-to-create-personas",children:"Using LLMs to Create Personas (Proxet)"})]})}),"\n",(0,i.jsxs)(r.p,{children:["Effective personas move beyond aesthetic descriptions and focus on ",(0,i.jsx)(r.strong,{children:"functional demographics"})," and ",(0,i.jsx)(r.strong,{children:"psychological traits"}),". Key components include:"]}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Background & Motivations:"}),' Defining the "why" behind the persona\u2019s actions to provide consistent decision-making.']}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Knowledge Scoping:"}),' Setting boundaries on what the persona knows (e.g., an "Expert Historian" vs. a "Novice Enthusiast") to avoid inconsistent expertise.']}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Dynamic Interaction:"}),' Using LLMs to simulate these personas in user-testing environments, allowing for the observation of "synthetic users" to predict real-world reactions.']}),"\n"]}),"\n",(0,i.jsx)(r.hr,{}),"\n",(0,i.jsx)(r.h2,{id:"technical-critique-implementation-realities",children:"Technical Critique: Implementation Realities"}),"\n",(0,i.jsx)(r.h3,{id:"1-learning-curves",children:"1. Learning Curves"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"The Precision Gap:"}),' Crafting a persona that is neither too rigid (leading to refusals) nor too loose (leading to "Assistant" tone leakage) requires iterative testing.']}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Instruction Overload:"}),' Adding too much biographical detail to a persona can distract the model from its primary task. The "Persona-Task" balance is a critical skill for prompt engineers.']}),"\n"]}),"\n",(0,i.jsx)(r.h3,{id:"2-hardware-and-performance-dependencies",children:"2. Hardware and Performance Dependencies"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Prompt Caching:"})," Large-scale personas and long system prompts significantly increase input token counts. Utilizing hardware/software stacks that support ",(0,i.jsx)(r.strong,{children:"Prompt Caching"})," (like vLLM or specialized API tiers) is essential to maintain low latency."]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Inference Costs:"}),' Every line of persona detail is an added cost per request. For high-volume applications, personas should be "minified" to include only functionally relevant traits.']}),"\n"]}),"\n",(0,i.jsx)(r.h3,{id:"3-operational-risks",children:"3. Operational Risks"}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Stereotyping & Bias:"}),' Personas built on generic descriptions may inadvertently trigger model biases or stereotypical responses, requiring constant "Constitutional AI" tuning.']}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Leakage & Injection:"})," System prompts and persona definitions are not secure. They are part of the context window and can be extracted by end-users using adversarial prompting techniques."]}),"\n"]})]})}function d(e={}){let{wrapper:r}={...(0,t.R)(),...e.components};return r?(0,i.jsx)(r,{...e,children:(0,i.jsx)(p,{...e})}):p(e)}},84429:function(e,r,n){n.d(r,{R:()=>o,x:()=>a});var s=n(96540);let i={},t=s.createContext(i);function o(e){let r=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(r):{...r,...e}},[r,e])}function a(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),s.createElement(t.Provider,{value:r},e.children)}}}]);